// Package emit generates Go source code for PDU decode/encode functions
// using the jennifer code generation library.
package emit

import (
	"fmt"
	"path/filepath"
	"strings"

	"github.com/USA-RedDragon/dmrgo/cmd/dmrgen/parse"
	. "github.com/dave/jennifer/jen" //nolint:revive,stylecheck,ST1001,staticcheck
)

const (
	bitPkg = "github.com/USA-RedDragon/dmrgo/dmr/bit"
	fecPkg = "github.com/USA-RedDragon/dmrgo/dmr/fec"
	crcPkg = "github.com/USA-RedDragon/dmrgo/dmr/crc"
	rsPkg  = "github.com/USA-RedDragon/dmrgo/dmr/fec/reed_solomon"
)

// FECCodecInfo maps FEC directive names to their decode function and import path.
type FECCodecInfo struct {
	ImportPath  string // e.g. "github.com/USA-RedDragon/dmrgo/dmr/fec/golay"
	GoPkgName   string // actual Go package name (may differ from directory)
	DecodeFn    string // e.g. "DecodeGolay2087"
	EncodeFn    string // e.g. "Encode" — func(byte) [N]bit.Bit
	InputSize   int    // full FEC codeword size in bits, e.g. 20
	DataBits    int    // data-only bits before FEC, e.g. 8
	PackedBytes bool   // true if codec operates on packed bytes (e.g. RS)
	TotalBytes  int    // for PackedBytes: total byte count (e.g. 12)
	DataBytes   int    // for PackedBytes: data byte count (e.g. 9)
}

//nolint:gochecknoglobals
var fecCodecs = map[string]FECCodecInfo{
	"golay_20_8_7": {
		ImportPath: "github.com/USA-RedDragon/dmrgo/dmr/fec/golay",
		GoPkgName:  "golay",
		DecodeFn:   "DecodeGolay2087",
		EncodeFn:   "Encode",
		InputSize:  20,
		DataBits:   8,
	},
	"quadratic_residue_16_7_6": {
		ImportPath: "github.com/USA-RedDragon/dmrgo/dmr/fec/quadratic_residue",
		GoPkgName:  "quadratic_residue",
		DecodeFn:   "Decode",
		EncodeFn:   "Encode",
		InputSize:  16,
		DataBits:   7,
	},
	"reed_solomon_12_9_4": {
		ImportPath:  rsPkg,
		GoPkgName:   "reedsolomon",
		DecodeFn:    "Decode",
		InputSize:   96,
		DataBits:    72,
		PackedBytes: true,
		TotalBytes:  12,
		DataBytes:   9,
	},
}

// pkgNameOverrides maps import paths to actual Go package names where they differ
// from the directory name. Jennifer uses the last path element by default.
//
//nolint:gochecknoglobals
var pkgNameOverrides = map[string]string{
	"github.com/USA-RedDragon/dmrgo/dmr/fec/quadratic_residue": "quadratic_residue",
	"github.com/USA-RedDragon/dmrgo/dmr/fec/reed_solomon":      "reedsolomon",
	"github.com/USA-RedDragon/dmrgo/dmr/fec/trellis":           "trellis34",
}

// resolveImportPath converts a short package name (e.g. "enums") to a full import path.
func resolveImportPath(pkgName, sourceFile string) string {
	// Map well-known package names to full import paths
	knownPkgs := map[string]string{
		"enums":            "github.com/USA-RedDragon/dmrgo/dmr/enums",
		"elements":         "github.com/USA-RedDragon/dmrgo/dmr/layer2/elements",
		"bit":              "github.com/USA-RedDragon/dmrgo/dmr/bit",
		"fec":              "github.com/USA-RedDragon/dmrgo/dmr/fec",
		"layer3Elements":   "github.com/USA-RedDragon/dmrgo/dmr/layer3/elements",
		"golay":            "github.com/USA-RedDragon/dmrgo/dmr/fec/golay",
		"quadraticResidue": "github.com/USA-RedDragon/dmrgo/dmr/fec/quadratic_residue",
		"reedSolomon":      "github.com/USA-RedDragon/dmrgo/dmr/fec/reed_solomon",
		"bptc":             "github.com/USA-RedDragon/dmrgo/dmr/fec/bptc",
		"trellis":          "github.com/USA-RedDragon/dmrgo/dmr/fec/trellis",
		"vocoder":          "github.com/USA-RedDragon/dmrgo/dmr/vocoder",
	}
	if p, ok := knownPkgs[pkgName]; ok {
		return p
	}
	// Fall back: assume it's a relative sibling package
	dir := filepath.Dir(sourceFile)
	return "github.com/USA-RedDragon/dmrgo/" + filepath.Join(dir, pkgName)
}

// GenerateFile produces the _decode_gen.go content for a set of PDU structs.
func GenerateFile(pdus []parse.PDUStruct, pkgName string) (*File, error) {
	f := NewFile(pkgName)

	// Build header comment, including spec references when available.
	header := "Code generated by dmrgen."
	var specRefs []string
	seen := map[string]bool{}
	for _, pdu := range pdus {
		if pdu.SpecRef != "" && !seen[pdu.SpecRef] {
			specRefs = append(specRefs, pdu.SpecRef)
			seen[pdu.SpecRef] = true
		}
	}
	if len(specRefs) > 0 {
		header += "\n"
		for _, ref := range specRefs {
			header += "\n" + ref
		}
		header += "\n"
	}
	header += "\nDO NOT EDIT."
	f.HeaderComment(header)

	// Register package name overrides so Jennifer uses the correct identifiers
	for importPath, pkgName := range pkgNameOverrides {
		f.ImportName(importPath, pkgName)
	}

	for _, pdu := range pdus {
		if err := emitDecode(f, pdu); err != nil {
			return nil, fmt.Errorf("generating decode for %s: %w", pdu.Name, err)
		}
		f.Line()
		emitEncode(f, pdu)
	}

	return f, nil
}

// emitDecode generates a DecodeXxx function for a PDU struct.
func emitDecode(f *File, pdu parse.PDUStruct) error {
	funcName := "Decode" + pdu.Name
	inputSize := pdu.InputSize

	// Add spec reference comment above the function if available.
	if pdu.SpecRef != "" {
		f.Comment(funcName + " decodes a " + pdu.Name + " per " + pdu.SpecRef)
	}

	// Determine if FEC pre-processing is needed
	var codec *FECCodecInfo
	if pdu.FEC != nil {
		c, ok := fecCodecs[pdu.FEC.Codec]
		if !ok {
			return fmt.Errorf("unknown FEC codec: %s", pdu.FEC.Codec)
		}
		codec = &c
		inputSize = codec.InputSize
	}

	// func DecodeXxx(data [N]bit.Bit) (Xxx, fec.FECResult) {
	f.Func().Id(funcName).Params(
		Id("data").Index(Lit(inputSize)).Qual(bitPkg, "Bit"),
	).Params(
		Id(pdu.Name),
		Qual(fecPkg, "FECResult"),
	).BlockFunc(func(g *Group) {
		g.Var().Id("result").Id(pdu.Name)

		hasCRC := pdu.CRC != nil
		hasPackedFEC := codec != nil && codec.PackedBytes
		hasBitFEC := codec != nil && !codec.PackedBytes

		if hasCRC || hasPackedFEC {
			// Both CRC and packed-bytes FEC need bit packing first
			totalBytes := inputSize / 8
			emitBitPacking(g, totalBytes)
		}

		if hasCRC {
			emitCRCCheck(g, pdu, inputSize)
		} else if hasPackedFEC {
			emitPackedFECDecode(g, codec, inputSize)
		} else if hasBitFEC {
			// Bit-level FEC (Golay, QR): operates directly on bit arrays
			g.List(Id("corrected"), Id("fecResult")).Op(":=").Qual(codec.ImportPath, codec.DecodeFn).Call(Id("data"))
			g.Id("result").Dot("FEC").Op("=").Id("fecResult")
			g.If(Op("!").Id("fecResult").Dot("Uncorrectable")).Block(
				Id("data").Op("=").Id("corrected"),
			)
		} else {
			g.Var().Id("fecResult").Qual(fecPkg, "FECResult")
		}

		// Emit field extractions (regular fields first, then dispatch)
		var dispatchFields []parse.Field
		for _, field := range pdu.Fields {
			if field.Name == "FEC" {
				continue // skip the FEC field itself
			}
			if field.Kind == parse.FieldDispatch {
				dispatchFields = append(dispatchFields, field)
				continue
			}
			emitFieldDecode(g, field, pdu)
		}

		// Emit dispatch switch if there are dispatch fields
		if len(dispatchFields) > 0 {
			emitDispatchSwitch(g, dispatchFields, pdu)
		}

		g.Return(Id("result"), Id("fecResult"))
	})

	return nil
}

// emitBitPacking generates code to pack bit.Bit array into []byte.
func emitBitPacking(g *Group, totalBytes int) {
	// var _packedBytes [N]byte
	g.Var().Id("_packedBytes").Index(Lit(totalBytes)).Byte()
	// for i := range N { for j := range 8 { _packedBytes[i] <<= 1; _packedBytes[i] |= byte(data[i*8+j]) } }
	g.For(Id("i").Op(":=").Range().Lit(totalBytes)).Block(
		For(Id("j").Op(":=").Range().Lit(8)).Block(
			Id("_packedBytes").Index(Id("i")).Op("<<=").Lit(1),
			Id("_packedBytes").Index(Id("i")).Op("|=").Byte().Call(
				Id("data").Index(Id("i").Op("*").Lit(8).Op("+").Id("j")),
			),
		),
	)
}

// emitCRCCheck generates CRC-CCITT validation code.
func emitCRCCheck(g *Group, pdu parse.PDUStruct, inputSize int) {
	crcDir := pdu.CRC

	// Apply XOR mask if specified
	if crcDir.HasMask {
		highByte := byte(crcDir.Mask >> 8)
		lowByte := byte(crcDir.Mask)
		totalBytes := inputSize / 8
		g.Id("_packedBytes").Index(Lit(totalBytes - 2)).Op("^=").Lit(highByte)
		g.Id("_packedBytes").Index(Lit(totalBytes - 1)).Op("^=").Lit(lowByte)
	}

	// CRC check
	g.Var().Id("fecResult").Qual(fecPkg, "FECResult")
	g.Id("fecResult").Dot("BitsChecked").Op("=").Lit(inputSize)
	g.If(Op("!").Qual(crcPkg, "CheckCRCCCITT").Call(Id("_packedBytes").Index(Empty(), Empty()))).Block(
		Id("fecResult").Dot("Uncorrectable").Op("=").True(),
	)
	g.Id("result").Dot("FEC").Op("=").Id("fecResult")

	// Store CRC value from the (possibly masked) packed bytes
	totalBytes := inputSize / 8
	g.Id("result").Dot("crc").Op("=").
		Uint16().Call(Id("_packedBytes").Index(Lit(totalBytes - 2))).Op("<<").Lit(8).
		Op("|").Uint16().Call(Id("_packedBytes").Index(Lit(totalBytes - 1)))
}

// emitPackedFECDecode generates packed-bytes FEC (e.g. Reed-Solomon) decode code.
func emitPackedFECDecode(g *Group, codec *FECCodecInfo, inputSize int) {
	// rsResult := reedsolomon.Decode(_packedBytes[:])
	g.Id("_rsResult").Op(":=").Qual(codec.ImportPath, codec.DecodeFn).Call(
		Id("_packedBytes").Index(Empty(), Empty()),
	)
	g.Id("fecResult").Op(":=").Qual(fecPkg, "FECResult").Values(Dict{
		Id("BitsChecked"):     Lit(inputSize),
		Id("ErrorsCorrected"): Id("_rsResult").Dot("ErrorsFound"),
		Id("Uncorrectable"):   Id("_rsResult").Dot("Uncorrectable"),
	})
	g.Id("result").Dot("FEC").Op("=").Id("fecResult")

	// If corrected, unpack corrected data bytes back into the data bit array
	g.If(Op("!").Id("_rsResult").Dot("Uncorrectable")).Block(
		For(Id("i").Op(":=").Range().Lit(codec.DataBytes)).Block(
			For(Id("j").Op(":=").Range().Lit(8)).Block(
				Id("data").Index(Id("i").Op("*").Lit(8).Op("+").Id("j")).Op("=").
					Qual(bitPkg, "Bit").Call(
					Parens(Id("_rsResult").Dot("Data").Index(Id("i")).Op(">>").
						Parens(Lit(7).Op("-").Id("j"))).Op("&").Lit(1),
				),
			),
		),
	)
}

// emitDispatchSwitch generates a switch statement that dispatches on a field value
// and decodes the appropriate sub-PDU into a pointer field.
func emitDispatchSwitch(g *Group, fields []parse.Field, pdu parse.PDUStruct) {
	if len(fields) == 0 {
		return
	}

	// All dispatch fields in a PDU share the same dispatch field name and bit range
	dispatchFieldName := fields[0].DispatchFieldName
	bitStart := fields[0].BitStart
	bitEnd := fields[0].BitEnd
	arraySize := bitEnd - bitStart + 1

	// Declare the payload bits variable
	tmpVar := "_dispatchBits"
	g.Var().Id(tmpVar).Index(Lit(arraySize)).Qual(bitPkg, "Bit")
	g.Copy(Id(tmpVar).Index(Empty(), Empty()), Id("data").Index(Lit(bitStart), Lit(bitEnd+1)))

	// Build the switch statement
	g.Switch(Id("result").Dot(dispatchFieldName)).BlockFunc(func(sw *Group) {
		for _, field := range fields {
			// Build case values
			caseValues := make([]Code, len(field.DispatchValues))
			for i, val := range field.DispatchValues {
				caseValues[i] = emitDispatchConstant(val, pdu)
			}

			// Determine the decode function name from the pointed type
			typeName := field.TypeName
			if field.IsPointer && field.PointedType != "" {
				typeName = field.PointedType
			}
			decodeFn := "Decode" + typeName

			sw.Case(caseValues...).Block(
				List(Id("_decoded"), Id("_")).Op(":=").Id(decodeFn).Call(Id(tmpVar)),
				Id("result").Dot(field.Name).Op("=").Op("&").Id("_decoded"),
			)
		}
	})
}

// emitDispatchConstant generates the jennifer Code for a dispatch constant reference.
// If the value contains a ".", it's a cross-package constant (e.g. "enums.FLCOGroupVoiceChannelUser").
// Otherwise it's a same-package constant (e.g. "CSBKBSOutboundActivationPDU").
func emitDispatchConstant(val string, pdu parse.PDUStruct) Code {
	if idx := strings.LastIndex(val, "."); idx >= 0 {
		pkg := val[:idx]
		name := val[idx+1:]
		importPath := resolveImportPath(pkg, pdu.SourceFile)
		return Qual(importPath, name)
	}
	return Id(val)
}

// emitFieldDecode generates the decode logic for a single field.
func emitFieldDecode(g *Group, field parse.Field, pdu parse.PDUStruct) {
	target := Id("result").Dot(field.Name)

	switch field.Kind {
	case parse.FieldBool:
		// result.FieldName = bit.BitsToBool(data[:], bitStart)
		g.Add(target).Op("=").Qual(bitPkg, "BitsToBool").Call(
			Id("data").Index(Empty(), Empty()),
			Lit(field.BitStart),
		)

	case parse.FieldUint:
		if len(field.ExtraBitRanges) > 0 {
			// Non-contiguous bits: accumulate segments MSB-first using a temp variable
			emitNonContiguousDecode(g, field, pdu)
		} else {
			// Choose the right bit extraction function based on width
			fn, castType := bitExtractFunc(field.BitWidth, field.GoType)
			call := Qual(bitPkg, fn).Call(
				Id("data").Index(Empty(), Empty()),
				Lit(field.BitStart),
				Lit(field.BitEnd-field.BitStart+1),
			)
			if needsCast(fn, field.GoType) {
				g.Add(target).Op("=").Add(qualType(field, pdu)).Call(call)
			} else {
				_ = castType
				g.Add(target).Op("=").Add(call)
			}
		}

	case parse.FieldInt:
		g.Add(target).Op("=").Qual(bitPkg, "BitsToInt").Call(
			Id("data").Index(Empty(), Empty()),
			Lit(field.BitStart),
			Lit(field.BitWidth),
		)

	case parse.FieldEnum:
		// Extract as int, then call FromInt
		extractExpr := Qual(bitPkg, "BitsToInt").Call(
			Id("data").Index(Empty(), Empty()),
			Lit(field.BitStart),
			Lit(field.BitWidth),
		)

		// Parse the FromInt function reference
		fromPkg, fromFn := splitQualified(field.EnumFromInt)
		importPath := resolveImportPath(fromPkg, pdu.SourceFile)

		// Check if FromInt returns error (two returns) or just value (one return)
		// We determine this from function name patterns:
		// LCSSFromInt returns just LCSS, FLCOFromInt returns (FLCO, error)
		if field.EnumReturnsErr {
			// Wrap in block scope to avoid "no new variables" redeclaration errors
			// when multiple enum-with-error fields appear in the same function.
			g.Block(
				List(Id("_enumVal"), Id("_")).Op(":=").Qual(importPath, fromFn).Call(extractExpr),
				target.Clone().Op("=").Id("_enumVal"),
			)
		} else {
			g.Add(target).Op("=").Qual(importPath, fromFn).Call(extractExpr)
		}

	case parse.FieldRaw:
		// Copy bits into a fixed-size array
		g.Copy(target.Clone().Index(Empty(), Empty()), Id("data").Index(Lit(field.BitStart), Lit(field.BitEnd+1)))

	case parse.FieldPacked:
		// Pack bits into bytes using bit.PackBits
		packed := Qual(bitPkg, "PackBits").Call(
			Id("data").Index(Lit(field.BitStart), Lit(field.BitEnd+1)),
		)
		if isFixedArray(field.GoType) {
			// Fixed-size array: must use copy
			g.Copy(target.Clone().Index(Empty(), Empty()), packed)
		} else {
			g.Add(target).Op("=").Add(packed)
		}

	case parse.FieldDelegate:
		// Delegate to a sub-struct's constructor: NewXxxFromBits([N]bit.Bit)
		constructorName := "New" + field.TypeName + "FromBits"
		var importPath string
		if field.IsQualified {
			importPath = resolveImportPath(field.TypePkg, pdu.SourceFile)
		}

		if field.Stride > 0 && field.ArrayLen > 0 {
			// Array delegate with stride: generate a loop
			tmpVar := "_elemBits"
			g.For(Id("_i").Op(":=").Lit(0), Id("_i").Op("<").Lit(field.ArrayLen), Id("_i").Op("++")).Block(
				Var().Id(tmpVar).Index(Lit(field.Stride)).Qual(bitPkg, "Bit"),
				Copy(Id(tmpVar).Index(Empty(), Empty()), Id("data").Index(
					Lit(field.BitStart).Op("+").Id("_i").Op("*").Lit(field.Stride),
					Lit(field.BitStart).Op("+").Id("_i").Op("*").Lit(field.Stride).Op("+").Lit(field.Stride),
				)),
				func() Code {
					var call Code
					if field.IsQualified {
						call = Qual(importPath, constructorName).Call(Id(tmpVar))
					} else {
						call = Id(constructorName).Call(Id(tmpVar))
					}
					return target.Clone().Index(Id("_i")).Op("=").Add(call)
				}(),
			)
		} else if field.DelegateNoPtr {
			// noptr delegates are uint typedefs — inline BitsToUint8 cast
			arraySize := field.BitEnd - field.BitStart + 1
			var typeQual Code
			if field.IsQualified {
				typeQual = Qual(importPath, field.TypeName)
			} else {
				typeQual = Id(field.TypeName)
			}
			g.Add(target).Op("=").Add(typeQual).Call(
				Qual(bitPkg, "BitsToUint8").Call(
					Id("data").Index(Lit(field.BitStart), Lit(field.BitEnd+1)),
					Lit(0),
					Lit(arraySize),
				),
			)
		} else {
			// Struct delegate with pointer constructor
			arraySize := field.BitEnd - field.BitStart + 1
			tmpVar := "_" + strings.ToLower(field.Name[:1]) + field.Name[1:] + "Bits"

			g.Var().Id(tmpVar).Index(Lit(arraySize)).Qual(bitPkg, "Bit")
			g.Copy(Id(tmpVar).Index(Empty(), Empty()), Id("data").Index(Lit(field.BitStart), Lit(field.BitEnd+1)))

			var constructorCall Code
			if field.IsQualified {
				constructorCall = Qual(importPath, constructorName).Call(Id(tmpVar))
			} else {
				constructorCall = Id(constructorName).Call(Id(tmpVar))
			}
			g.Add(target).Op("=").Op("*").Add(constructorCall)
		}

	case parse.FieldLongitude:
		// Longitude = float32(rawInt) * float32(360.0 / math.Pow(2, bitWidth))
		g.Add(target).Op("=").Float32().Call(
			Qual(bitPkg, "BitsToInt").Call(
				Id("data").Index(Empty(), Empty()),
				Lit(field.BitStart),
				Lit(field.BitWidth),
			),
		).Op("*").Float32().Call(
			Lit(360.0).Op("/").Qual("math", "Pow").Call(Lit(2.0), Lit(float64(field.BitWidth))),
		)

	case parse.FieldLatitude:
		// Latitude = float32(rawInt) * float32(180.0 / math.Pow(2, bitWidth))
		g.Add(target).Op("=").Float32().Call(
			Qual(bitPkg, "BitsToInt").Call(
				Id("data").Index(Empty(), Empty()),
				Lit(field.BitStart),
				Lit(field.BitWidth),
			),
		).Op("*").Float32().Call(
			Lit(180.0).Op("/").Qual("math", "Pow").Call(Lit(2.0), Lit(float64(field.BitWidth))),
		)

	case parse.FieldDispatch:
		// Dispatch fields are handled separately in emitDispatchSwitch
		// (no-op here — they are emitted after all regular fields)
	}
}

// emitEncode generates an EncodeXxx function for a PDU struct.
// For FEC-protected PDUs, the output includes FEC parity (full codeword).
func emitEncode(f *File, pdu parse.PDUStruct) {
	funcName := "Encode" + pdu.Name

	// Add spec reference comment above the function if available.
	if pdu.SpecRef != "" {
		f.Comment(funcName + " encodes a " + pdu.Name + " per " + pdu.SpecRef)
	}

	var codec *FECCodecInfo
	if pdu.FEC != nil {
		c, ok := fecCodecs[pdu.FEC.Codec]
		if ok {
			codec = &c
		}
	}

	hasCRC := pdu.CRC != nil
	hasPackedFEC := codec != nil && codec.PackedBytes
	hasBitFEC := codec != nil && !codec.PackedBytes

	// Output is the full codeword size
	outputSize := pdu.InputSize
	if codec != nil {
		outputSize = codec.InputSize
	}

	f.Func().Id(funcName).Params(
		Id("s").Op("*").Id(pdu.Name),
	).Index(Lit(outputSize)).Qual(bitPkg, "Bit").BlockFunc(func(g *Group) {
		if hasBitFEC {
			// Bit-level FEC (Golay, QR): build data bits, then FEC-encode
			dataBits := codec.DataBits
			g.Var().Id("data").Index(Lit(dataBits)).Qual(bitPkg, "Bit")
			emitEncodeFields(g, pdu)
			g.Return(Qual(codec.ImportPath, codec.EncodeFn).Call(
				Qual(bitPkg, "BitsToValue").Call(Id("data").Index(Empty(), Empty())),
			))
		} else if hasCRC || hasPackedFEC {
			// CRC or packed FEC: build data bits, then pack+CRC/RS-encode
			g.Var().Id("data").Index(Lit(outputSize)).Qual(bitPkg, "Bit")
			emitEncodeFields(g, pdu)
			if hasCRC {
				emitCRCEncode(g, pdu, outputSize)
			}
			if hasPackedFEC {
				emitPackedFECEncode(g, codec, outputSize)
			}
			g.Return(Id("data"))
		} else {
			g.Var().Id("data").Index(Lit(outputSize)).Qual(bitPkg, "Bit")
			emitEncodeFields(g, pdu)
			g.Return(Id("data"))
		}
	})
}

// emitEncodeFields emits encoding for all fields (regular + dispatch).
func emitEncodeFields(g *Group, pdu parse.PDUStruct) {
	var dispatchFields []parse.Field
	for _, field := range pdu.Fields {
		if field.Name == "FEC" {
			continue
		}
		if field.Kind == parse.FieldDispatch {
			dispatchFields = append(dispatchFields, field)
			continue
		}
		emitFieldEncode(g, field, pdu)
	}
	if len(dispatchFields) > 0 {
		emitDispatchEncode(g, dispatchFields, pdu)
	}
}

// emitDispatchEncode generates a switch that encodes the active dispatch field.
func emitDispatchEncode(g *Group, fields []parse.Field, pdu parse.PDUStruct) {
	if len(fields) == 0 {
		return
	}

	bitStart := fields[0].BitStart
	bitEnd := fields[0].BitEnd

	// switch {
	// case s.BSOutboundActivationPDU != nil:
	//     pduBits := EncodeBSOutboundActivationPDU(s.BSOutboundActivationPDU)
	//     copy(data[16:80], pduBits[:])
	// ...
	// }
	g.Switch().BlockFunc(func(sw *Group) {
		for _, field := range fields {
			typeName := field.TypeName
			if field.IsPointer && field.PointedType != "" {
				typeName = field.PointedType
			}
			encodeFn := "Encode" + typeName
			sw.Case(Id("s").Dot(field.Name).Op("!=").Nil()).Block(
				Id("_pduBits").Op(":=").Id(encodeFn).Call(Id("s").Dot(field.Name)),
				Copy(Id("data").Index(Lit(bitStart), Lit(bitEnd+1)), Id("_pduBits").Index(Empty(), Empty())),
			)
		}
	})
}

// emitCRCEncode generates CRC-CCITT calculation and embedding for encoding.
func emitCRCEncode(g *Group, pdu parse.PDUStruct, outputSize int) {
	totalBytes := outputSize / 8
	dataBytes := totalBytes - 2 // CRC is last 2 bytes

	// Pack the data bits (excluding CRC bytes) into _packedBytes
	g.Var().Id("_encBytes").Index(Lit(dataBytes)).Byte()
	g.For(Id("i").Op(":=").Range().Lit(dataBytes)).Block(
		For(Id("j").Op(":=").Range().Lit(8)).Block(
			Id("_encBytes").Index(Id("i")).Op("<<=").Lit(1),
			Id("_encBytes").Index(Id("i")).Op("|=").Byte().Call(
				Id("data").Index(Id("i").Op("*").Lit(8).Op("+").Id("j")),
			),
		),
	)

	// Calculate CRC
	g.Id("_crcVal").Op(":=").Qual(crcPkg, "CalculateCRCCCITT").Call(Id("_encBytes").Index(Empty(), Empty()))

	// CRC bytes (big-endian, swapped like MMDVM: crc8[0]=low, crc8[1]=high)
	g.Id("_crcHigh").Op(":=").Byte().Call(Id("_crcVal").Op(">>").Lit(8))
	g.Id("_crcLow").Op(":=").Byte().Call(Id("_crcVal"))

	// Apply mask if present
	if pdu.CRC != nil && pdu.CRC.HasMask {
		highByte := byte(pdu.CRC.Mask >> 8)
		lowByte := byte(pdu.CRC.Mask)
		g.Id("_crcHigh").Op("^=").Lit(highByte)
		g.Id("_crcLow").Op("^=").Lit(lowByte)
	}

	// Unpack CRC into data bits (last 16 bits)
	crcBitStart := dataBytes * 8
	g.For(Id("j").Op(":=").Range().Lit(8)).Block(
		Id("data").Index(Lit(crcBitStart).Op("+").Id("j")).Op("=").
			Qual(bitPkg, "Bit").Call(
			Parens(Id("_crcHigh").Op(">>").Parens(Lit(7).Op("-").Id("j"))).Op("&").Lit(1),
		),
	)
	g.For(Id("j").Op(":=").Range().Lit(8)).Block(
		Id("data").Index(Lit(crcBitStart+8).Op("+").Id("j")).Op("=").
			Qual(bitPkg, "Bit").Call(
			Parens(Id("_crcLow").Op(">>").Parens(Lit(7).Op("-").Id("j"))).Op("&").Lit(1),
		),
	)
}

// emitPackedFECEncode generates Reed-Solomon encoding for the encode path.
func emitPackedFECEncode(g *Group, codec *FECCodecInfo, outputSize int) {
	// Pack data bytes (first N data bytes)
	g.Var().Id("_encData").Index(Lit(codec.DataBytes)).Byte()
	g.For(Id("i").Op(":=").Range().Lit(codec.DataBytes)).Block(
		For(Id("j").Op(":=").Range().Lit(8)).Block(
			Id("_encData").Index(Id("i")).Op("<<=").Lit(1),
			Id("_encData").Index(Id("i")).Op("|=").Byte().Call(
				Id("data").Index(Id("i").Op("*").Lit(8).Op("+").Id("j")),
			),
		),
	)

	// RS encode: returns ([]byte, error)
	g.List(Id("_encoded"), Id("_")).Op(":=").Qual(codec.ImportPath, "Encode").Call(
		Id("_encData").Index(Empty(), Empty()),
	)

	// Unpack all encoded bytes (data + parity) back into data bits
	totalBytes := outputSize / 8
	g.For(Id("i").Op(":=").Range().Lit(totalBytes)).Block(
		For(Id("j").Op(":=").Range().Lit(8)).Block(
			Id("data").Index(Id("i").Op("*").Lit(8).Op("+").Id("j")).Op("=").
				Qual(bitPkg, "Bit").Call(
				Parens(Id("_encoded").Index(Id("i")).Op(">>").
					Parens(Lit(7).Op("-").Id("j"))).Op("&").Lit(1),
			),
		),
	)
}

// emitFieldEncode generates the encode logic for a single field.
func emitFieldEncode(g *Group, field parse.Field, _ parse.PDUStruct) {
	source := Id("s").Dot(field.Name)

	switch field.Kind {
	case parse.FieldBool:
		// if s.FieldName { data[bit] = 1 }
		g.If(source.Clone()).Block(
			Id("data").Index(Lit(field.BitStart)).Op("=").Lit(1),
		)

	case parse.FieldUint:
		if len(field.ExtraBitRanges) > 0 {
			// Non-contiguous bits: decompose value into segments
			emitNonContiguousEncode(g, field)
		} else {
			fn := bitStoreFunc(field.BitWidth, field.GoType)
			bits := Qual(bitPkg, fn).Call(
				castToStoreFuncType(source.Clone(), field.GoType, fn),
				Lit(field.BitWidth),
			)
			g.Copy(
				Id("data").Index(Lit(field.BitStart), Lit(field.BitEnd+1)),
				bits,
			)
		}

	case parse.FieldInt:
		// BitsFromUint32 handles it, just needs a cast
		bits := Qual(bitPkg, "BitsFromUint32").Call(
			Uint32().Call(source.Clone()),
			Lit(field.BitWidth),
		)
		g.Copy(
			Id("data").Index(Lit(field.BitStart), Lit(field.BitEnd+1)),
			bits,
		)

	case parse.FieldEnum:
		// Cast enum to int, then to uint for BitsFromUint
		fn := bitStoreFunc(field.BitWidth, "uint8")
		storeType := storeParamType(fn)
		bits := Qual(bitPkg, fn).Call(
			Add(storeType).Call(source.Clone()),
			Lit(field.BitWidth),
		)
		g.Copy(
			Id("data").Index(Lit(field.BitStart), Lit(field.BitEnd+1)),
			bits,
		)

	case parse.FieldRaw:
		g.Copy(
			Id("data").Index(Lit(field.BitStart), Lit(field.BitEnd+1)),
			source.Clone().Index(Empty(), Empty()),
		)

	case parse.FieldPacked:
		// Unpack bytes back to individual bits
		var src *Statement
		if isFixedArray(field.GoType) {
			src = source.Clone().Index(Empty(), Empty()) // s.Data[:]
		} else {
			src = source.Clone()
		}
		g.Copy(
			Id("data").Index(Lit(field.BitStart), Lit(field.BitEnd+1)),
			Qual(bitPkg, "UnpackBits").Call(src),
		)

	case parse.FieldDelegate:
		arraySize := field.BitEnd - field.BitStart + 1
		if field.Stride > 0 && field.ArrayLen > 0 {
			// Array delegate with stride: call Encode() on each element
			g.For(Id("_i").Op(":=").Lit(0), Id("_i").Op("<").Lit(field.ArrayLen), Id("_i").Op("++")).Block(
				Id("_elemBits").Op(":=").Add(source.Clone().Index(Id("_i"))).Dot("Encode").Call(),
				Copy(
					Id("data").Index(
						Lit(field.BitStart).Op("+").Id("_i").Op("*").Lit(field.Stride),
						Lit(field.BitStart).Op("+").Id("_i").Op("*").Lit(field.Stride).Op("+").Lit(field.Stride),
					),
					Id("_elemBits").Index(Empty(), Empty()),
				),
			)
		} else if arraySize == 8 {
			// Assume ToByte() exists for 8-bit delegates
			g.Copy(
				Id("data").Index(Lit(field.BitStart), Lit(field.BitEnd+1)),
				Qual(bitPkg, "BitsFromUint8").Call(
					source.Clone().Dot("ToByte").Call(),
					Lit(8),
				),
			)
		} else if field.DelegateNoPtr {
			// noptr delegates are uint typedefs — cast to uint8 and pack bits
			g.Copy(
				Id("data").Index(Lit(field.BitStart), Lit(field.BitEnd+1)),
				Qual(bitPkg, "BitsFromUint8").Call(
					Uint8().Call(source.Clone()),
					Lit(arraySize),
				),
			)
		} else {
			// For other sizes, call Encode() which returns [N]bit.Bit
			tmpVar := "_" + strings.ToLower(field.Name[:1]) + field.Name[1:] + "Bits"
			g.Id(tmpVar).Op(":=").Add(source.Clone()).Dot("Encode").Call()
			g.Copy(
				Id("data").Index(Lit(field.BitStart), Lit(field.BitEnd+1)),
				Id(tmpVar).Index(Empty(), Empty()),
			)
		}

	case parse.FieldLongitude:
		// Reverse: int(lon / (360.0 / float32(1 << bitWidth)))
		g.Copy(
			Id("data").Index(Lit(field.BitStart), Lit(field.BitEnd+1)),
			Qual(bitPkg, "BitsFromUint32").Call(
				Uint32().Call(
					source.Clone().Op("/").Float32().Call(
						Lit(360.0).Op("/").Qual("math", "Pow").Call(Lit(2.0), Lit(float64(field.BitWidth))),
					),
				),
				Lit(field.BitWidth),
			),
		)

	case parse.FieldLatitude:
		// Reverse: int(lat / (180.0 / float32(1 << bitWidth)))
		g.Copy(
			Id("data").Index(Lit(field.BitStart), Lit(field.BitEnd+1)),
			Qual(bitPkg, "BitsFromUint32").Call(
				Uint32().Call(
					source.Clone().Op("/").Float32().Call(
						Lit(180.0).Op("/").Qual("math", "Pow").Call(Lit(2.0), Lit(float64(field.BitWidth))),
					),
				),
				Lit(field.BitWidth),
			),
		)

	case parse.FieldDispatch:
		// Dispatch fields are handled separately in emitDispatchEncode
		// (no-op here)
	}
}

// emitNonContiguousDecode generates decode logic for a non-contiguous uint field.
// For example, bits:3+12-15 means bit 3 is the MSB and bits 12-15 are the lower nibble.
// It accumulates segments in a temp variable: extract first range, shift left, OR next range, etc.
func emitNonContiguousDecode(g *Group, field parse.Field, pdu parse.PDUStruct) {
	tmpName := "_tmp" + field.Name
	fn, _ := bitExtractFunc(field.BitWidth, field.GoType)
	firstWidth := field.BitEnd - field.BitStart + 1

	// var _tmpField uint8 (using the extract function's natural type)
	switch fn {
	case "BitsToUint8":
		g.Var().Id(tmpName).Uint8()
	case "BitsToUint16":
		g.Var().Id(tmpName).Uint16()
	default:
		g.Var().Id(tmpName).Uint32()
	}

	// _tmpField = BitsToUintN(data[:], firstStart, firstWidth)
	g.Id(tmpName).Op("=").Qual(bitPkg, fn).Call(
		Id("data").Index(Empty(), Empty()),
		Lit(field.BitStart),
		Lit(firstWidth),
	)

	// For each extra range: shift left by extra width, then OR the extracted bits
	for _, r := range field.ExtraBitRanges {
		extraWidth := r[1] - r[0] + 1
		g.Id(tmpName).Op("<<=").Lit(extraWidth)
		g.Id(tmpName).Op("|=").Qual(bitPkg, fn).Call(
			Id("data").Index(Empty(), Empty()),
			Lit(r[0]),
			Lit(extraWidth),
		)
	}

	// result.Field = cast(_tmpField)
	target := Id("result").Dot(field.Name)
	if needsCast(fn, field.GoType) {
		g.Add(target).Op("=").Add(qualType(field, pdu)).Call(Id(tmpName))
	} else {
		g.Add(target).Op("=").Id(tmpName)
	}
}

// emitNonContiguousEncode generates encode logic for a non-contiguous uint field.
// Decomposes the value into segments (MSB-first) and stores each in its bit range.
func emitNonContiguousEncode(g *Group, field parse.Field) {
	source := Id("s").Dot(field.Name)
	fn := bitStoreFunc(field.BitWidth, field.GoType)
	firstWidth := field.BitEnd - field.BitStart + 1

	// Calculate remaining bits after the first range
	remaining := 0
	for _, r := range field.ExtraBitRanges {
		remaining += r[1] - r[0] + 1
	}

	// First range: extract MSB portion by shifting right past remaining bits
	firstVal := castToStoreFuncType(source.Clone(), field.GoType, fn)
	if remaining > 0 {
		firstVal = castToStoreFuncType(
			Parens(Add(storeParamType(fn)).Call(source.Clone())).Op(">>").Lit(remaining),
			storeParamGoType(fn), fn,
		)
	}
	g.Copy(
		Id("data").Index(Lit(field.BitStart), Lit(field.BitEnd+1)),
		Qual(bitPkg, fn).Call(firstVal, Lit(firstWidth)),
	)

	// Each extra range: extract the corresponding portion
	for _, r := range field.ExtraBitRanges {
		extraWidth := r[1] - r[0] + 1
		remaining -= extraWidth

		var segVal *Statement
		if remaining > 0 {
			segVal = castToStoreFuncType(
				Parens(Add(storeParamType(fn)).Call(source.Clone())).Op(">>").Lit(remaining),
				storeParamGoType(fn), fn,
			)
		} else {
			segVal = castToStoreFuncType(source.Clone(), field.GoType, fn)
		}
		g.Copy(
			Id("data").Index(Lit(r[0]), Lit(r[1]+1)),
			Qual(bitPkg, fn).Call(segVal, Lit(extraWidth)),
		)
	}
}

// Helper functions

func bitExtractFunc(width int, _ string) (string, string) {
	switch {
	case width <= 8:
		return "BitsToUint8", "uint8"
	case width <= 16:
		return "BitsToUint16", "uint16"
	default:
		return "BitsToUint32", "uint32"
	}
}

func bitStoreFunc(width int, _ string) string {
	switch {
	case width <= 8:
		return "BitsFromUint8"
	case width <= 16:
		return "BitsFromUint16"
	default:
		return "BitsFromUint32"
	}
}

func storeParamType(fn string) *Statement {
	switch fn {
	case "BitsFromUint8":
		return Uint8()
	case "BitsFromUint16":
		return Uint16()
	default:
		return Uint32()
	}
}

// storeParamGoType returns the Go type string corresponding to a BitsFromUintN function.
func storeParamGoType(fn string) string {
	switch fn {
	case "BitsFromUint8":
		return "uint8"
	case "BitsFromUint16":
		return "uint16"
	default:
		return "uint32"
	}
}

func castToStoreFuncType(expr *Statement, goType, fn string) *Statement {
	expected := map[string]string{
		"BitsFromUint8":  "uint8",
		"BitsFromUint16": "uint16",
		"BitsFromUint32": "uint32",
	}
	if goType == expected[fn] {
		return expr
	}
	return Add(storeParamType(fn)).Call(expr)
}

func needsCast(extractFn, goType string) bool {
	switch extractFn {
	case "BitsToUint8":
		return goType != "uint8" && goType != "byte"
	case "BitsToUint16":
		return goType != "uint16"
	case "BitsToUint32":
		return goType != "uint32"
	case "BitsToInt":
		return goType != "int"
	}
	return false
}

func qualType(field parse.Field, pdu parse.PDUStruct) *Statement {
	if field.IsQualified {
		importPath := resolveImportPath(field.TypePkg, pdu.SourceFile)
		return Qual(importPath, field.TypeName)
	}
	return Id(field.GoType)
}

func splitQualified(s string) (string, string) {
	if idx := strings.LastIndex(s, "."); idx >= 0 {
		return s[:idx], s[idx+1:]
	}
	return "", s
}

// isFixedArray returns true if the Go type is a fixed-size array (e.g. "[12]byte")
// as opposed to a slice (e.g. "[]byte").
func isFixedArray(goType string) bool {
	return strings.HasPrefix(goType, "[") && !strings.HasPrefix(goType, "[]")
}
